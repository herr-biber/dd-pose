{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DD-Pose getting started\n",
    "This jupyter notebook shows you how to access the raw data and annotations of the DD-Pose dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dd_pose.dataset import Dataset\n",
    "from dd_pose.dataset_item import DatasetItem\n",
    "from dd_pose.image_decorator import ImageDecorator\n",
    "from dd_pose.jupyter_helpers import showimage\n",
    "from dd_pose.evaluation_helpers import T_headfrontal_camdriver, T_camdriver_headfrontal\n",
    "from dd_pose.visualization_helpers import get_dashboard\n",
    "\n",
    "import transformations as tr\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `Dataset` contains `dataset item dictionaries`.  \n",
    "You can choose between splits `'trainval'`, `'test'` and `'all'`:\n",
    "* `trainval`: training and validation split. Raw data and head pose measurements\n",
    "* `test`: held-out test split. No head pose measurements\n",
    "* `all`: union of the two above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Dataset(split='all')\n",
    "len(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`d.get_dataset_items()` yeilds a generator for all `dataset item dictionaries` in a dataset.  \n",
    "A `dataset_item dictionary` is represented by a `subject` (int), a `scenario` (int) and a `humanhash` (str).  \n",
    "The `humanhash` is there to disambiguate multiple `scenario`s of the same type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(d.get_dataset_items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also get a `dataset item dictionary` by providing `subject`, `scenario` and `humanhash` directly.  \n",
    "The file `resources/dataset-items-trainval.txt` covers the existing dataset items of the `trainval` split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head resources/dataset-items-trainval.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "di_dict = d.get(subject_id=1, scenario_id=3, humanhash='sodium-finch-fillet-spring') # trainval\n",
    "# di_dict = d.get(subject_id=6, scenario_id=0, humanhash='quebec-aspen-washington-social') # test\n",
    "di_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access data\n",
    "\n",
    "A `DatasetItem` object encapsulates all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "di = DatasetItem(di_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A measurement in a `DatasetItem` is indexed by a timestamp.  \n",
    "`di.get_stamps()` gets all timestamps as long integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stamps = di.get_stamps()\n",
    "len(stamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stamps[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose arbitrary stamp and print data for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stamp = stamps[153]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get gps information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "di.get_gps(stamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heading above ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "di.get_heading(stamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the image of the left driver cam\n",
    "... and convert from 16bit depth to 8bit depth by shifting 8 bits to the right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, pcm = di.get_img_driver_left(stamp, shift=True)\n",
    "img.shape, img.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pcm represents the associated pinhole camera model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcm.P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can project 3d points onto the image plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcm.project3dToPixel((0, 0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the image of the left driver camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showimage(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the docu cam image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_docu, pcm_docu = di.get_img_docu(stamp)\n",
    "img_docu.shape, img_docu.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showimage(img_docu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Occlusion state of face (see paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "di.get_occlusion_state(stamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steering wheel angle and acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "di.get_stw_angle(stamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations\n",
    "Transformations are given in homogeneous coordinates.  \n",
    "The terminology is:  \n",
    "`point_A = T_A_B * point_B`\n",
    "\n",
    "`T_A_B` is a homogeneous 4x4 matrix which transforms a `point_B` from frame `B` to a `point_A` in frame `A`.  \n",
    "Points are homogeneous 4 element column vectors `(x, y, z, 1.0)`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static homogeneous transformation from body frame (car) to camdriver (the optical frame of the left driver camera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "di.get_T_camdriver_body()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static homogeneous transformation from camdocu optical frame to camdriver optical frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "di.get_T_camdriver_camdocu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static homogeneous transformation from gps frame to camdriver optical frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "di.get_T_camdriver_gps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Head pose: homogeneous transformation from head frame to camdriver optical frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_camdriver_head = di.get_T_camdriver_head(stamp)\n",
    "T_camdriver_head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw head pose into camdriver image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, pcm = di.get_img_driver_left(stamp, shift=True)\n",
    "img_bgr = np.dstack((img, img, img))\n",
    "\n",
    "image_decorator = ImageDecorator(img_bgr, pcm)\n",
    "if T_camdriver_head is not None:\n",
    "    image_decorator.draw_axis(T_camdriver_head)\n",
    "else:\n",
    "    image_decorator.draw_text(\"no T_camdriver_head\")\n",
    "showimage(img_bgr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw head pose into camdocu image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_docu, pcm_docu = di.get_img_docu(stamp)\n",
    "image_decorator = ImageDecorator(img_docu, pcm_docu)\n",
    "\n",
    "# Get transformation from head into camdocu frame by \"chaining\"\n",
    "# Note how the 'camdriver' cancels out by multiplication\n",
    "T_camdocu_camdriver = np.linalg.inv(di.get_T_camdriver_camdocu())\n",
    "if T_camdriver_head is not None:\n",
    "    T_camdocu_head = np.dot(T_camdocu_camdriver, T_camdriver_head)\n",
    "    image_decorator.draw_axis(T_camdocu_head)\n",
    "else:\n",
    "    image_decorator.draw_text(\"No T_camdriver_head\")\n",
    "\n",
    "# Also draw camdriver frame into image\n",
    "image_decorator.draw_axis(T_camdocu_camdriver)\n",
    "\n",
    "showimage(img_docu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Angular representation of head pose\n",
    "There are many angular representations.  \n",
    "You get get a conventional representation by 'static axis rotation' towards frontally looking head, \n",
    "i.e. `roll = pitch = yaw = 0` represents a head looking frontally towards the camera\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if T_camdriver_head is not None:\n",
    "    T_headfrontal_head = np.dot(T_headfrontal_camdriver, T_camdriver_head)\n",
    "    roll, pitch, yaw = tr.euler_from_matrix(T_headfrontal_head, 'sxyz')\n",
    "    roll, pitch, yaw # in rad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize `T_camdriver_headfrontal`\n",
    "Draw `headfrontal` frame into camdocu image.  \n",
    "`x` points inside the camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_docu, pcm_docu = di.get_img_docu(stamp)\n",
    "image_decorator = ImageDecorator(img_docu, pcm_docu)\n",
    "T_camdocu_camdriver = np.linalg.inv(di.get_T_camdriver_camdocu())\n",
    "T_camdocu_headfrontal = np.dot(T_camdocu_camdriver, T_camdriver_headfrontal)\n",
    "image_decorator.draw_axis(T_camdocu_headfrontal)\n",
    "showimage(img_docu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use all-in-one function `get_dashboard`\n",
    "Shows all information in one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dashboard = get_dashboard(di, stamp)\n",
    "showimage(img_dashboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
